# ml_pipeline/train.py
import pandas as pd
import io
import sys
import collections
from sklearn.model_selection import TimeSeriesSplit
from common.config import Config, MLConfig
from common.db import get_sync_engine
from common.logger import logger
from ml_pipeline.features import add_features
from ml_pipeline.model import build_model
from ml_pipeline.preprocessing import preprocess_data
from ml_pipeline.evaluation import evaluate_model

def main():
    engine = get_sync_engine(Config.ALPACA_DB)  # Az integrÃ¡lt adatokat tartalmazza az Alpaca adatbÃ¡zis
    raw_data = pd.read_sql("SELECT * FROM integrated_market_data", engine)
    
    if raw_data.empty:
        logger.error("âŒ Nincs adat a trÃ©ninghez.")
        return
    
    missing = [col for col in ['open', 'high', 'low', 'close', 'volume'] if col not in raw_data.columns]
    if missing:
        logger.error(f"âŒ HiÃ¡nyzÃ³ oszlopok a trÃ©ning adatokbÃ³l: {missing}")
        return
    else:
        logger.info("âœ… Minden szÃ¼ksÃ©ges oszlop megtalÃ¡lhatÃ³ a trÃ©ning adatokban.")
    
    # Ha hiÃ¡nyzik a 'target' oszlop, szÃ¡mÃ­tsuk ki: 1, ha a kÃ¶vetkezÅ‘ zÃ¡rÃ³Ã¡r magasabb, egyÃ©bkÃ©nt 0.
    if 'target' not in raw_data.columns:
        raw_data['target'] = (raw_data['close'].shift(-1) > raw_data['close']).astype(int)
    
    raw_data = add_features(raw_data)
    logger.info(f"âœ… Technikai indikÃ¡torok szÃ¡mÃ­tÃ¡sa kÃ©sz. Ã–sszes rekord: {len(raw_data)}")
    
    required_count = 100
    if len(raw_data) < required_count:
        logger.warning(f"âš ï¸ Csak {len(raw_data)} rekord Ã¡ll rendelkezÃ©sre, mÃ­g {required_count} szÃ¼ksÃ©ges.")
    else:
        logger.info(f"âœ… ElÃ©g adat Ã¡ll rendelkezÃ©sre az indikÃ¡tor szÃ¡mÃ­tÃ¡shoz ({len(raw_data)} rekord).")
    
    tscv = TimeSeriesSplit(n_splits=MLConfig.TRAINING_SPLITS)
    train_idx, test_idx = next(tscv.split(raw_data))
    train, test = raw_data.iloc[train_idx], raw_data.iloc[test_idx]
    
    # Csak numerikus jellemzÅ‘k kivÃ¡lasztÃ¡sa (timestamp, symbol, target kivÃ©telÃ©vel)
    features = [col for col in train.columns if col not in ['timestamp', 'symbol', 'target']]
    numeric_features = train[features].select_dtypes(include=["number"]).columns.tolist()
    
    X_train, y_train = train[numeric_features], train['target']
    X_test, y_test = test[numeric_features], test['target']
    
    X_train, X_test = preprocess_data(X_train, X_test, MLConfig.PCA_COMPONENTS)
    
    model = build_model()
    
    # Capture a LightGBM hiba/figyelmeztetÃ©seket (stderr kimenetÃ©t)
    stderr_capture = io.StringIO()
    old_stderr = sys.stderr
    sys.stderr = stderr_capture
    try:
        model.fit(X_train, y_train)
    finally:
        sys.stderr = old_stderr
    warnings_text = stderr_capture.getvalue()
    # Csak azokat a sorokat nÃ©zzÃ¼k, amelyek a [LightGBM] szÃ¶veget tartalmazzÃ¡k
    lgbm_lines = [line for line in warnings_text.splitlines() if "[LightGBM]" in line]
    if lgbm_lines:
        counter = collections.Counter(lgbm_lines)
        for message, count in counter.items():
            logger.warning(f"[LightGBM] {message} occurred {count} times.")
    
    logger.info("ğŸš€ Modell trÃ©ning sikeresen befejezÅ‘dÃ¶tt.")
    
    preds = model.predict(X_test)
    probs = model.predict_proba(X_test)[:, 1]
    returns = test['close'].pct_change().shift(-1).fillna(0)
    
    eval_details = evaluate_model(y_test, preds, probs, returns)
    
    results = test[['timestamp', 'symbol']].copy()
    results['prediction'] = preds
    results['probability'] = probs
    results.to_sql('trading_predictions', engine, if_exists='append', index=False)
    
    logger.info("ğŸš€ ModellezÃ©si eredmÃ©nyek sikeresen mentve.")
    logger.info(f"ML Pipeline rÃ©szletek:\n{eval_details}")

if __name__ == "__main__":
    main()
